# t66y_spider.py
import os
import sys
import requests
import logging
from bs4 import BeautifulSoup

# =================== é…ç½®åŒº ====================
BASE_URL = "http://t66y.com"
IMAGE_DIR = "downloaded_images"

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                  "AppleWebKit/537.36 (KHTML, like Gecko) "
                  "Chrome/120.0 Safari/537.36"
}

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
# ================================================================

def get_thread_links(list_url):
    """æŠ“å–åˆ—è¡¨é¡µï¼Œè¿”å›ç¬¦åˆ [äºæ´²]/[äºšæ´²] çš„ä¸»é¢˜é“¾æ¥"""
    try:
        resp = requests.get(list_url, headers=HEADERS, timeout=15)
        resp.encoding = "gbk"
        soup = BeautifulSoup(resp.text, "lxml")
    except Exception as e:
        logger.error(f"âŒ è¯·æ±‚åˆ—è¡¨é¡µå¤±è´¥: {e}")
        return []

    links = []
    for td in soup.find_all("td", class_="tal"):
        text = td.get_text(strip=True)
        if "[äºšæ´²]" in text or "[äºæ´²]" in text:  # æ”¯æŒç®€ä½“/ç¹ä½“
            a = td.find("a", href=True)
            if a:
                href = a["href"]
                if href.startswith("/"):
                    href = BASE_URL + href
                links.append(href)
                logger.info(f"ğŸŸ¢ å‘ç°ä¸»é¢˜: {href}")
    return links

def download_images_from_thread(url, save_root):
    """è¿›å…¥å¸–å­ä¸‹è½½å›¾ç‰‡"""
    try:
        resp = requests.get(url, headers=HEADERS, timeout=15)
        resp.encoding = "gbk"
        soup = BeautifulSoup(resp.text, "lxml")
    except Exception as e:
        logger.error(f"âŒ åŠ è½½å¸–å­å¤±è´¥ {url} - {e}")
        return

    # è·å–å¸–å­æ ‡é¢˜
    title_tag = soup.find("title")
    if title_tag:
        title = title_tag.get_text(strip=True)
    else:
        title = url.split("/")[-1]
    # æ›¿æ¢éæ³•æ–‡ä»¶åå­—ç¬¦
    title = title.replace("/", "_").replace("\\", "_").replace(":", "_")[:80]

    thread_dir = os.path.join(save_root, title)
    os.makedirs(thread_dir, exist_ok=True)

    img_tags = soup.find_all("img")
    count = 0
    for img in img_tags:
        src = img.get("data-link") or img.get("ess-data") or img.get("src")
        if not src:
            continue
        if src.startswith("/"):
            src = BASE_URL + src
        try:
            img_data = requests.get(src, headers=HEADERS, timeout=15).content
            ext = os.path.splitext(src)[1] or ".jpg"
            fname = os.path.join(thread_dir, f"{count:03d}{ext}")
            with open(fname, "wb") as f:
                f.write(img_data)
            count += 1
        except Exception as e:
            logger.warning(f"âš ï¸ ä¸‹è½½å¤±è´¥ {src} - {e}")

    if count > 0:
        logger.info(f"âœ… ä¸‹è½½å®Œæˆ: {title} å…± {count} å¼ å›¾ç‰‡")
    else:
        logger.info(f"âš ï¸ {title} æ²¡æ‰¾åˆ°å›¾ç‰‡")

def main(start_page, end_page):
    os.makedirs(IMAGE_DIR, exist_ok=True)

    for page in range(start_page, end_page + 1):
        list_url = f"{BASE_URL}/thread0806.php?fid=8" if page == 1 else f"{BASE_URL}/thread0806.php?fid=8&search=&page={page}"
        logger.info(f"ğŸ“„ æŠ“å–åˆ—è¡¨é¡µ: {list_url}")
        thread_links = get_thread_links(list_url)
        if not thread_links:
            logger.info("âš ï¸ å½“å‰é¡µæ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„ä¸»é¢˜")
            continue

        for link in thread_links:
            download_images_from_thread(link, IMAGE_DIR)

    logger.info("ğŸ”š æ‰€æœ‰ä»»åŠ¡å®Œæˆ")

if __name__ == "__main__":
    if len(sys.argv) != 3:
        print("ç”¨æ³•: python t66y_spider.py <èµ·å§‹é¡µç > <ç»“æŸé¡µç >")
        sys.exit(1)

    try:
        start_page = int(sys.argv[1])
        end_page = int(sys.argv[2])
    except ValueError:
        print("âŒ é¡µç å¿…é¡»æ˜¯æ•´æ•°")
        sys.exit(1)

    if start_page < 1 or start_page > end_page:
        print("âŒ é¡µç èŒƒå›´ä¸æ­£ç¡®")
        sys.exit(1)

    main(start_page, end_page)
